{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#having images in class subfolder"
      ],
      "metadata": {
        "id": "rKeBxl7eBIkB"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#unzipping\n",
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile('/content/catDog.zip', 'r')\n",
        "zip_ref.extractall('/content')\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "HrfwsFHJF7w7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "V1KXxvTkE2NY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow. keras import layers\n",
        "from tensorflow. keras. preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_height=28\n",
        "img_width = 28\n",
        "batch_size = 1\n",
        "model = keras. Sequential([\n",
        "    layers. Input ((28, 28, 1)),\n",
        "    layers.Conv2D(16, 3, padding= 'same'),\n",
        "    layers.Conv2D(32, 3, padding='same'),\n",
        "    layers. MaxPooling2D(),\n",
        "    layers .Flatten (),\n",
        "    layers. Dense (10),\n",
        "])"
      ],
      "metadata": {
        "id": "u2xCe-kbDd_r"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#method 1 using dataset from directory"
      ],
      "metadata": {
        "id": "fNPMyGobEvCU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds_train = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    '/content/catDog/',\n",
        "    labels='inferred', #labels taken from folder name in alpha order\n",
        "    label_mode = \"int\", # categorical, binary\n",
        "    #class_names=['0', '1','2',13',]\n",
        "    color_mode='grayscale', #color of image\n",
        "    batch_size=batch_size,\n",
        "    image_size=(28, 28), # reshape if not in this size\n",
        "    shuffle=True,\n",
        "    seed=123, #for controlled randomness\n",
        "    validation_split=0.25,\n",
        "    subset=\"training\"\n",
        ")"
      ],
      "metadata": {
        "id": "dT9lsuvsFE0S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bcfccd6-f785-4d3d-b3bd-9f5e0975add1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8 files belonging to 2 classes.\n",
            "Using 6 files for training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def augment (x, y):\n",
        "  image = tf. image.random_brightness(x, max_delta=0.05)\n",
        "  return image, y\n",
        "\n",
        "ds_train = ds_train.map(augment)\n",
        "\n",
        "# Custom Loops\n",
        "for epochs in range(10) :\n",
        "  for x, y in ds_train:\n",
        "    # train here\n",
        "    pass"
      ],
      "metadata": {
        "id": "i4tnNuXvri2Y"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model. compile(\n",
        "    optimizer=keras.optimizers.Adam (),\n",
        "    loss=[keras.losses. SparseCategoricalCrossentropy (from_logits=True),\n",
        "          ],\n",
        "    metrics=[\"accuracy\"],\n",
        ")"
      ],
      "metadata": {
        "id": "BhMu0BZvPYKr"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit (ds_train, epochs=10, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyFaHOnvPozD",
        "outputId": "93d80518-24d8-4134-82be-43b6f7ac3a4b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "6/6 - 1s - loss: 61.2264 - accuracy: 0.1667 - 966ms/epoch - 161ms/step\n",
            "Epoch 2/10\n",
            "6/6 - 0s - loss: 65.1356 - accuracy: 0.6667 - 37ms/epoch - 6ms/step\n",
            "Epoch 3/10\n",
            "6/6 - 0s - loss: 54.7519 - accuracy: 0.6667 - 39ms/epoch - 7ms/step\n",
            "Epoch 4/10\n",
            "6/6 - 0s - loss: 21.4632 - accuracy: 0.8333 - 53ms/epoch - 9ms/step\n",
            "Epoch 5/10\n",
            "6/6 - 0s - loss: 17.0121 - accuracy: 0.6667 - 36ms/epoch - 6ms/step\n",
            "Epoch 6/10\n",
            "6/6 - 0s - loss: 1.9868e-08 - accuracy: 1.0000 - 38ms/epoch - 6ms/step\n",
            "Epoch 7/10\n",
            "6/6 - 0s - loss: 3.5779 - accuracy: 0.8333 - 33ms/epoch - 6ms/step\n",
            "Epoch 8/10\n",
            "6/6 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - 39ms/epoch - 7ms/step\n",
            "Epoch 9/10\n",
            "6/6 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - 35ms/epoch - 6ms/step\n",
            "Epoch 10/10\n",
            "6/6 - 0s - loss: 0.0000e+00 - accuracy: 1.0000 - 35ms/epoch - 6ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x784a421077f0>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#method 2 using ImgaeDataGenerator and flow from directory"
      ],
      "metadata": {
        "id": "fS5bbrVyP0QD"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=5,\n",
        "    zoom_range= (0.95, 0.95),\n",
        "    horizontal_flip=False,\n",
        "    vertical_flip=False,\n",
        "    data_format='channels_last',\n",
        "    validation_split=0.0,\n",
        "    #dtype=tf.float32,\n",
        ")\n",
        "\n",
        "train_generator = datagen.flow_from_directory (\n",
        "    '/content/catDog/',\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    color_mode='grayscale',\n",
        "    class_mode='sparse', #for integer class labels\n",
        "    shuffle=True,\n",
        "    subset='training',\n",
        "    seed=123\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAZn9QwlRIyS",
        "outputId": "c731f461-ccb7-4b75-eae4-0e5d7d2cbcc2"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def training():\n",
        "  pass\n",
        "# Custom Loops\n",
        "for epoch in range (10):\n",
        "  num_batches = 0\n",
        "  for x, y in ds_train:\n",
        "    num_batches += 1\n",
        "    # do training\n",
        "    training()\n",
        "\n",
        "    if num_batches == 8: # len(train_dataset)/batch_size\n",
        "      break"
      ],
      "metadata": {
        "id": "Poj14wOqTJSh"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Redo model.compile to reset the optimizer states\n",
        "model.compile (\n",
        "    optimizer=keras.optimizers.Adam (),\n",
        "    loss= keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[\"accuracy\"],\n",
        ")"
      ],
      "metadata": {
        "id": "ZpcPOhVmT4fF"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# using model.fit (note steps_per_epoch)\n",
        "model.fit(train_generator,\n",
        "          epochs=10,\n",
        "          steps_per_epoch=8, #it is same as if num_batches == 8: in custom loop\n",
        "          verbose=2,\n",
        ")\n",
        "# if we had a validation generator:\n",
        "#validation_data=validation_generator, #valiation_steps=len (validation_set)/batch_size),"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ut75wRhJUC0u",
        "outputId": "846fda03-19cf-4e68-a329-0ae72023c9f0"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "8/8 - 1s - loss: 1.5970 - accuracy: 0.5000 - 1s/epoch - 137ms/step\n",
            "Epoch 2/10\n",
            "8/8 - 0s - loss: 0.7413 - accuracy: 0.6250 - 72ms/epoch - 9ms/step\n",
            "Epoch 3/10\n",
            "8/8 - 0s - loss: 0.5660 - accuracy: 0.8750 - 74ms/epoch - 9ms/step\n",
            "Epoch 4/10\n",
            "8/8 - 0s - loss: 0.4506 - accuracy: 0.7500 - 69ms/epoch - 9ms/step\n",
            "Epoch 5/10\n",
            "8/8 - 0s - loss: 0.3046 - accuracy: 1.0000 - 79ms/epoch - 10ms/step\n",
            "Epoch 6/10\n",
            "8/8 - 0s - loss: 0.2747 - accuracy: 1.0000 - 66ms/epoch - 8ms/step\n",
            "Epoch 7/10\n",
            "8/8 - 0s - loss: 0.2565 - accuracy: 0.8750 - 67ms/epoch - 8ms/step\n",
            "Epoch 8/10\n",
            "8/8 - 0s - loss: 0.1485 - accuracy: 1.0000 - 75ms/epoch - 9ms/step\n",
            "Epoch 9/10\n",
            "8/8 - 0s - loss: 0.1351 - accuracy: 1.0000 - 70ms/epoch - 9ms/step\n",
            "Epoch 10/10\n",
            "8/8 - 0s - loss: 0.1030 - accuracy: 1.0000 - 65ms/epoch - 8ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x784a40a42f20>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#method 3 when having dataframe"
      ],
      "metadata": {
        "id": "9aQZL5_jWP3R"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "directory = 'data/mist_images_csv/'\n",
        "df = pd.read_csv (directory + 'train.csv')\n",
        "file_paths = df [' file_name' ].values\n",
        "\n",
        "labels = df ['label'].values\n",
        "\n",
        "ds_train = tf .data.Dataset.from_tensor_slices((file_paths, labels)) #it is similar to do zip, that map 1st path to 1st label\n",
        "#and so on\n",
        "\n",
        "def read_image (image_file, label):\n",
        "  image = tf.io.read_file (directory + image_file)\n",
        "  image = tf. image. decode_image (image, channels=1, dtype=tf. float32)\n",
        "  return image, label\n",
        "\n",
        "def augment (image, label):\n",
        "# data augmentation here\n",
        "  return image, label\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "xYUq_WBDUPyo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds_train = ds_train.map (read_image) .map(augment) .batch (2)"
      ],
      "metadata": {
        "id": "hRxwNLKoWW4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range (10):\n",
        "  for x, y in ds_train:\n",
        "  # train here\n",
        "    pass"
      ],
      "metadata": {
        "id": "EK9mT2KtWW2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#method 4- having all the images in one folder and label is present in file name"
      ],
      "metadata": {
        "id": "NjTE0lT1WW0i"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ [\"TF_CPP_MIN_LOG_ LEVEL\"] = \"2\"\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import pathlib # pathlib is in standard library"
      ],
      "metadata": {
        "id": "buoUsf7kWWyj"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 2\n",
        "img_height = 28\n",
        "img_width = 28\n",
        "directory = 'data/mist_images_only/'\n",
        "\n",
        "\n",
        "ds_train = tf.data.Dataset.list_files(str (pathlib.Path(directory+ \"*.jpg\" ))) #we have to define pattern in this"
      ],
      "metadata": {
        "id": "H25i9f46WWr3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_path (file_path):\n",
        "  image = tf.io.read_file (file_path)\n",
        "  image = tf. image. decode_jpeg (image, channels=1)\n",
        "  label = tf.strings.split(file_path, '\\\\') #\\\\ this is path sepaerator\n",
        "  label = tf.strings.substr(label, pos=0, len=1)[2]\n",
        "  label = tf.strings.to_number (label, out_type=tf.int64)\n",
        "  return image, label"
      ],
      "metadata": {
        "id": "LmMToQnEISOf"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds_train = ds_train.map(process_path).batch(batch_size)"
      ],
      "metadata": {
        "id": "UE_dJ4B1Iblr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}