{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "WIdJj-FBER6I"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow. keras import layers, regularizers\n",
        "from tensorflow. keras .datasets import cifar10"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10. load_data()\n",
        "x_train = x_train.astype (\"float32\") / 255.0\n",
        "x_test = x_test.astype (\"float32\") / 255.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xG_iG9XaEtVq",
        "outputId": "088f1eea-4203-4154-be3f-7d9fd70bcc6e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def my_model():\n",
        "  input=layers.Input(shape=(32,32,3))\n",
        "  x=layers.Conv2D(32,\n",
        "                  3,\n",
        "                  padding='valid',\n",
        "                  kernel_regularizer=regularizers.l2(0.001))(input)\n",
        "  x=layers.BatchNormalization()(x) #batch norm also have effect of regularisation\n",
        "  x=keras.activations.relu(x)\n",
        "  x=layers.MaxPooling2D()(x)\n",
        "  x=layers.Conv2D(64,\n",
        "                  5,\n",
        "                  padding='same',\n",
        "                  kernel_regularizer=regularizers.l2(0.001))(x)\n",
        "  x=layers.BatchNormalization()(x)\n",
        "  x=keras.activations.relu(x)\n",
        "  x=layers.Conv2D(128,\n",
        "                  3,\n",
        "                  padding='same',\n",
        "                  kernel_regularizer=regularizers.l2(0.001))(x)\n",
        "  x=layers.BatchNormalization()(x)\n",
        "  x=keras.activations.relu(x)\n",
        "  x=layers.Flatten()(x)\n",
        "  x=layers.Dense(128,\n",
        "                 activation='relu',\n",
        "                 kernel_regularizer=regularizers.l2(0.001))(x) #we are adding regularization then dropouts also as dropout switch neurons between\n",
        "                 #these two dense layers and generalize prediction\n",
        "  x=layers.Dropout(0.5)(x)\n",
        "  output=layers.Dense(10)(x)\n",
        "\n",
        "  return keras.Model(inputs=input,outputs=output)\n",
        "\n"
      ],
      "metadata": {
        "id": "2yXjal3DEu_V"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=my_model()\n",
        "model.compile(loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              optimizer=keras.optimizers.Adam(learning_rate=3e-5),\n",
        "              metrics=['Accuracy'])"
      ],
      "metadata": {
        "id": "yneJNTPBGDdR"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train,y_train,epochs=1,verbose=2,batch_size=64)\n",
        "model.evaluate(x_test,y_test,verbose=2,batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dht-hlWaGGKr",
        "outputId": "d4127270-7561-4f57-f859-6d8ea1021e04"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 - 320s - loss: 2.1537 - Accuracy: 0.3662 - 320s/epoch - 409ms/step\n",
            "313/313 - 17s - loss: 1.7435 - Accuracy: 0.5109 - 17s/epoch - 55ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.7434523105621338, 0.5109000205993652]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#it takes longer to train when we add dropout as neurons get shut down so need more epochs"
      ],
      "metadata": {
        "id": "TZDotdvWGK8q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}