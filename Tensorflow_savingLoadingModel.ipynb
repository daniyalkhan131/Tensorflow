{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SrncWwIHHQxj"
      },
      "outputs": [],
      "source": [
        "#saving loading and serializing a model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow. keras import layers, regularizers\n",
        "import os\n",
        "import pandas as pd\n",
        "from tensorflow.keras.datasets import mnist"
      ],
      "metadata": {
        "id": "_OBnoYT5HZf4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist. load_data()\n",
        "x_train = x_train. reshape (-1, 28*28) .astype (\"float32\") / 255.0\n",
        "x_test = x_test. reshape (-1, 28*28) .astype (\"float32\") / 255.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkmXJlTWHlAz",
        "outputId": "f82cc1a9-592a-41c9-af72-7f415b4de57b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1 save and load model weights\n",
        "# 2 save and load entire model (serializing model)\n",
        "      # - Save weights\n",
        "      # - Model architecture\n",
        "      # - Training Configuration (model.compile())\n",
        "      # - Optimizer and states\n",
        "\n",
        "#when we save and load entire model, it saved as datastructure, that means we can load on different tensorflow frameworks\n",
        "#like tf lite, tf javascript,"
      ],
      "metadata": {
        "id": "pGod9pbaIjYb"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1= keras.Sequential(\n",
        "    [\n",
        "        layers.Input(shape=(28*28,)),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dense(10)\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "HGudXyTKHx6h"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input=layers.Input(shape=(28*28,))\n",
        "x=layers.Dense(64)(input)\n",
        "output=layers.Dense(10)(x)\n",
        "model2=keras.Model(inputs=[input], outputs=[output])"
      ],
      "metadata": {
        "id": "tJKgHNmCIAME"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModel (keras.Model):\n",
        "\n",
        "  def __init__ (self, num_classes=10) :\n",
        "    super(MyModel, self).__init__()\n",
        "    self.dense1 = layers.Dense(64)\n",
        "    self.dense2 = layers.Dense(num_classes)\n",
        "\n",
        "  def call(self, input_tensor):\n",
        "    x = tf.nn.relu(self.dense1(input_tensor))\n",
        "    return self.dense2(x)\n",
        "\n",
        "model3=MyModel()\n",
        "\n",
        "#if have to save this model weight then have to define config method and in newer\n",
        "#version possibly it got removed can check docs for this\n",
        "#use saving full model for this"
      ],
      "metadata": {
        "id": "5o5z0fihHmit"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.compile (optimizer=keras.optimizers.Adam(),\n",
        "                loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                metrics=[\"accuracy\"],\n",
        ")\n",
        "model1.fit(x_train, y_train, batch_size=64, epochs=3, verbose=2)\n",
        "model1.evaluate (x_test, y_test, batch_size=64, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xiZKk1e_H17Z",
        "outputId": "5648d1dd-2379-482a-f80d-37e19531351e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "938/938 - 3s - loss: 0.3471 - accuracy: 0.9042 - 3s/epoch - 4ms/step\n",
            "Epoch 2/3\n",
            "938/938 - 2s - loss: 0.1775 - accuracy: 0.9484 - 2s/epoch - 2ms/step\n",
            "Epoch 3/3\n",
            "938/938 - 2s - loss: 0.1342 - accuracy: 0.9603 - 2s/epoch - 2ms/step\n",
            "157/157 - 0s - loss: 0.1240 - accuracy: 0.9621 - 339ms/epoch - 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.12397653609514236, 0.9621000289916992]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1.save_weights('save_model/')\n",
        "#we can specify save format also\n",
        "# model1.save_weights('save_model/', save_format='h5')"
      ],
      "metadata": {
        "id": "bdW2xosyJWmg"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#now we have to create archi. same as we trained with and saved weights\n",
        "model1= keras.Sequential(\n",
        "    [\n",
        "        layers.Input(shape=(28*28,)),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dense(10)\n",
        "    ]\n",
        ")\n",
        "\n",
        "model1.load_weights('save_model/')\n",
        "model1.compile (optimizer=keras.optimizers.Adam(),\n",
        "                loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                metrics=[\"accuracy\"],\n",
        ")\n",
        "model1.evaluate (x_test, y_test, batch_size=64, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vQJuS9GJeDc",
        "outputId": "c9b3666e-ed12-44ae-d2da-79d2e96bb9eb"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "157/157 - 0s - loss: 0.1240 - accuracy: 0.9621 - 409ms/epoch - 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.12397653609514236, 0.9621000289916992]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#we cannot do like\n",
        "input=layers.Input(shape=(28*28,))\n",
        "x=layers.Dense(64)(input)\n",
        "output=layers.Dense(10)(x)\n",
        "model2=keras.Model(inputs=[input], outputs=[output])\n",
        "\n",
        "model2.load_weights('save_model/')\n",
        "\n",
        "model2.compile (optimizer=keras.optimizers.Adam(),\n",
        "                loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                metrics=[\"accuracy\"],\n",
        ")\n",
        "model2.evaluate (x_test, y_test, batch_size=64, verbose=2)\n",
        "\n",
        "#we can see accuracy is different that means weights are not properly loaded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMzwTIGqKDCS",
        "outputId": "174db3fb-f725-4c45-9812-fe469f4d3667"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "157/157 - 0s - loss: 1.5299 - accuracy: 0.7139 - 405ms/epoch - 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.5299452543258667, 0.7139000296592712]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#for saving full model\n",
        "\n",
        "model1.save('complete_save_model/')"
      ],
      "metadata": {
        "id": "r49C_4ZFKeNC"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#now without creating archi we can load\n",
        "model1=keras.models.load_model('complete_save_model/')\n",
        "model1.evaluate (x_test, y_test, batch_size=64, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s03lBeZlLqKU",
        "outputId": "e6b0609f-d8df-4803-9773-c41ae8d18598"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "157/157 - 1s - loss: 0.1240 - accuracy: 0.9621 - 506ms/epoch - 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.12397653609514236, 0.9621000289916992]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w58ZMO1qMGBS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}